# streamlit_app.py
import os
import json
import time
import datetime as dt
from typing import List, Dict, Any, Tuple

import streamlit as st
import tiktoken
from openai import OpenAI

# ë²„ì „ ì •ë³´
_VERSION = "1.0.0"
_TITLE = "ğŸ’¬ Chatbot "+_VERSION


#st.set_page_config(page_title="ğŸ’¬ Chatbot (Responses API + Tools + tiktoken)", page_icon="ğŸ§ ")
st.set_page_config(page_title=_TITLE, page_icon="ğŸ§ ")

# =========================
# Sidebar: Settings
# =========================
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    default_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", ""))
    openai_api_key = st.text_input("OpenAI API Key", type="password", value=default_key)

    # Responses APIì—ì„œ ì“¸ ëª¨ë¸ë“¤ (í•„ìš”ì‹œ ìµœì‹  ëª¨ë¸ëª…ìœ¼ë¡œ êµì²´)
    model = st.selectbox(
        "Model (Responses API)",
        options=[
            "gpt-4o-mini",
            "gpt-4o",
            "gpt-3.5-turbo",
        ],
        index=0
    )
    temperature = st.slider("Temperature", 0.0, 1.5, 0.7, 0.1)
    max_output_tokens = st.slider("Max output tokens", 128, 4096, 1024, 64)
    safety_margin_tokens = st.number_input("Safety margin tokens", min_value=256, max_value=8192, value=1024, step=64)
    system_prompt = st.text_area(
        "System prompt",
        value="You are a helpful, concise assistant. Reply in the user's language.",
        height=120
    )
    enable_tools = st.toggle("Enable tool calling (math_sum, get_current_time)", value=True)

#st.title("ğŸ’¬ Chatbot (Responses API + Tools + tiktoken)")
st.title(_TITLE)
st.caption("tiktoken ê¸°ë°˜ í† í° ì¹´ìš´íŒ…/ìë™ íŠ¸ë ì¼€ì´ì…˜ + Responses API ìŠ¤íŠ¸ë¦¬ë° + í•¨ìˆ˜ í˜¸ì¶œ ë°ëª¨")

# =========================
# Model context window & encodings (heuristic map)
# =========================
# ì‹¤ì„œë¹„ìŠ¤ì—ì„œëŠ” ê³µì‹ ìŠ¤í™ ì‹œíŠ¸ í™•ì¸ ê¶Œì¥. ì—¬ê¸°ì„  í”í•œ ê°’ë“¤ ì‚¬ìš©.
MODEL_CONTEXT_MAP = {
    "gpt-4o-mini": 128_000,
    "gpt-4o": 128_000,
    "gpt-3.5-turbo": 16_385,
}
# tiktoken ì¸ì½”ë”© ë§µ(ëª¨ë¸ ê³„ì—´ë³„ ëŒ€ì²´)
# ìµœì‹  ëª¨ë¸(o/X ê³„ì—´)ì€ ëŒ€ë¶€ë¶„ cl100k_baseë¡œ ì˜ ë™ì‘í•©ë‹ˆë‹¤. ë§ëŠ” ì¸ì½”ë”ê°€ ì—†ìœ¼ë©´ fallback.
MODEL_ENCODER_MAP = {
    "gpt-4o-mini": "cl100k_base",
    "gpt-4o": "cl100k_base",
    "gpt-3.5-turbo": "cl100k_base",
}

def get_context_window(m: str) -> int:
    return MODEL_CONTEXT_MAP.get(m, 128_000)

def get_encoder_name(m: str) -> str:
    return MODEL_ENCODER_MAP.get(m, "cl100k_base")

def count_tokens_text(text: str, encoder_name: str) -> int:
    enc = tiktoken.get_encoding(encoder_name)
    return len(enc.encode(text))

def count_tokens_messages(messages: List[Dict[str, str]], encoder_name: str) -> int:
    """
    ê°„ë‹¨í•œ ê·¼ì‚¬ì¹˜: role/contentë¥¼ í•©ì³ ë¬¸ìì—´ë¡œ ë¶™ì—¬ í† í° ì¹´ìš´íŠ¸.
    Responses APIëŠ” inputì— messages ë¦¬ìŠ¤íŠ¸ë¥¼ ë„£ì§€ë§Œ, ì—¬ê¸°ì„  ê·¼ì‚¬ ê³„ì‚°ìœ¼ë¡œ ì¶©ë¶„.
    """
    # "[role]: content\n" í˜•íƒœë¡œ ì§ë ¬í™” í›„ ì¹´ìš´íŠ¸ (ë©”íƒ€í† í° ì•½ê°„ì˜ ì˜¤ì°¨ ìˆìŒ)
    blob = ""
    for m in messages:
        blob += f"{m['role']}:\n{m['content']}\n"
    return count_tokens_text(blob, encoder_name)

def truncate_messages_by_tokens(
    system_prompt: str,
    history: List[Dict[str, str]],
    user_msg: Dict[str, str],
    model: str,
    max_output_tokens: int,
    safety_margin: int
) -> Tuple[List[Dict[str, str]], Dict[str, int]]:
    """
    ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ë‚´ì— ë“¤ì–´ì˜¤ë„ë¡ íˆìŠ¤í† ë¦¬ë¥¼ ë’¤ì—ì„œë¶€í„° ì˜ë¼ë‚´ê¸°.
    - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + íˆìŠ¤í† ë¦¬(ì˜ë¼ëƒ„) + ì‚¬ìš©ì ë©”ì‹œì§€
    - ë‚¨ê²¨ë‘¬ì•¼ í•  ì¶œë ¥ í† í° + ì„¸ì´í”„í‹° ë§ˆì§„ í™•ë³´
    """
    context_window = get_context_window(model)
    encoder_name = get_encoder_name(model)

    # ìš°ì„  ì „ë¶€ í¬í•¨í•œ ë’¤ í† í° ê³„ì‚°
    base_messages = [{"role": "system", "content": system_prompt}] + history + [user_msg]
    total_tokens = count_tokens_messages(base_messages, encoder_name)

    # í—ˆìš© ì…ë ¥ í† í° = ì»¨í…ìŠ¤íŠ¸ - (ì¶œë ¥ í† í° + ì„¸ì´í”„í‹° ë§ˆì§„)
    max_input_tokens = max(1024, context_window - (max_output_tokens + safety_margin))

    cut_count = 0
    kept_history = history[:]

    while total_tokens > max_input_tokens and kept_history:
        # ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¶€í„° ì œê±°
        kept_history.pop(0)
        cut_count += 1
        base_messages = [{"role": "system", "content": system_prompt}] + kept_history + [user_msg]
        total_tokens = count_tokens_messages(base_messages, encoder_name)

    # ìµœì¢… ë©”ì‹œì§€
    final_messages = [{"role": "system", "content": system_prompt}] + kept_history + [user_msg]

    stats = {
        "context_window": context_window,
        "max_input_tokens": max_input_tokens,
        "estimated_input_tokens": total_tokens,
        "cut_count": cut_count
    }
    return final_messages, stats

# =========================
# Simple tool implementations (server-side)
# =========================
def tool_math_sum(numbers: List[float]) -> float:
    try:
        return float(sum(numbers))
    except Exception:
        return float("nan")

def tool_get_current_time(tz: str = "Asia/Seoul") -> str:
    # ê°„ë‹¨ êµ¬í˜„: íƒ€ì„ì¡´ ë¯¸ì ìš©(ë°ëª¨). ì‹¤ì œë¡  pytz/zoneinfo ì‚¬ìš© ê¶Œì¥.
    now = dt.datetime.now()
    return now.strftime("%Y-%m-%d %H:%M:%S")

# Responses APIì— ë“±ë¡í•  ë„êµ¬ ìŠ¤í‚¤ë§ˆ
TOOLS_SPEC = [
    {
        "type": "function",
        "function": {
            "name": "math_sum",
            "description": "Return the sum of a list of numbers.",
            "parameters": {
                "type": "object",
                "properties": {
                    "numbers": {
                        "type": "array",
                        "items": {"type": "number"},
                        "description": "A list of numbers to sum."
                    }
                },
                "required": ["numbers"],
                "additionalProperties": False
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_current_time",
            "description": "Get the current local time as a string.",
            "parameters": {
                "type": "object",
                "properties": {
                    "tz": {"type": "string", "description": "IANA timezone string, e.g., Asia/Seoul"}
                },
                "required": [],
                "additionalProperties": False
            }
        }
    }
]

def execute_tool_call(name: str, arguments: Dict[str, Any]) -> str:
    """ë„êµ¬ë¥¼ ì‹¤ì œ ì‹¤í–‰í•˜ê³  ë¬¸ìì—´ ê²°ê³¼ë¥¼ ë°˜í™˜."""
    if name == "math_sum":
        nums = arguments.get("numbers", [])
        result = tool_math_sum(nums)
        return json.dumps({"sum": result}, ensure_ascii=False)
    if name == "get_current_time":
        tz = arguments.get("tz", "Asia/Seoul")
        result = tool_get_current_time(tz)
        return json.dumps({"now": result, "tz": tz}, ensure_ascii=False)
    return json.dumps({"error": f"Unknown tool: {name}"}, ensure_ascii=False)

# =========================
# Session state
# =========================
if "messages" not in st.session_state:
    st.session_state.messages: List[Dict[str, str]] = []

# ê¸°ì¡´ ë©”ì‹œì§€ ì¶œë ¥
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ëŒ€í™” ì œì–´ ë²„íŠ¼
c1, c2 = st.columns(2)
with c1:
    if st.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()
with c2:
    if st.button("ğŸ’¾ ëŒ€í™” JSON ë‚´ë³´ë‚´ê¸°"):
        st.download_button(
            label="ë‹¤ìš´ë¡œë“œ (ì•„ë˜ ë²„íŠ¼ í´ë¦­)",
            data=json.dumps(st.session_state.messages, ensure_ascii=False, indent=2),
            file_name=f"chat_{int(time.time())}.json",
            mime="application/json"
        )

# ì…ë ¥ì°½
user_text = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦")

# =========================
# Responses API call (streaming + tools)
# =========================
if not openai_api_key:
    st.info("ğŸ”‘ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="ğŸ—ï¸")
else:
    client = OpenAI(api_key=openai_api_key)

    if user_text:
        user_text = user_text.strip()
        if not user_text:
            st.warning("ë¹ˆ ë©”ì‹œì§€ëŠ” ë³´ë‚¼ ìˆ˜ ì—†ì–´ìš”.")
        else:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ë°˜ì˜/í‘œì‹œ
            st.session_state.messages.append({"role": "user", "content": user_text})
            with st.chat_message("user"):
                st.markdown(user_text)

            # --- tiktoken ê¸°ë°˜ ìë™ íŠ¸ë ì¼€ì´ì…˜ ---
            # Responses APIëŠ” inputì— messagesë¥¼ ê·¸ëŒ€ë¡œ ë„£ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
            # ì—¬ê¸°ì„  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + íˆìŠ¤í† ë¦¬ + í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ í¬í•¨.
            history_only = [m for m in st.session_state.messages[:-1]]  # ë§ˆì§€ë§‰ì€ í˜„ì¬ user
            current_user = {"role": "user", "content": user_text}
            final_messages, tok_stats = truncate_messages_by_tokens(
                system_prompt=system_prompt,
                history=history_only,
                user_msg=current_user,
                model=model,
                max_output_tokens=max_output_tokens,
                safety_margin=safety_margin_tokens,
            )

            # UIë¡œ í† í° í†µê³„ í‘œì‹œ(ì„ íƒ)
            with st.expander("í† í°/ì»¨í…ìŠ¤íŠ¸ í†µê³„ ë³´ê¸°", expanded=False):
                st.json(tok_stats)

            # --- Responses API ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ ---
            with st.chat_message("assistant"):
                placeholder = st.empty()
                full_text = ""

                try:
                    # Responses APIëŠ” inputì— messages í¬ë§·ì„ ê·¸ëŒ€ë¡œ ì¤„ ìˆ˜ ìˆìŒ
                    # tool ì‚¬ìš© í—ˆìš© ì‹œ tools ì „ë‹¬
                    stream_kwargs = dict(
                        model=model,
                        input=final_messages,
                        temperature=temperature,
                        max_output_tokens=max_output_tokens,
                    )
                    if enable_tools:
                        stream_kwargs["tools"] = TOOLS_SPEC
                        stream_kwargs["tool_choice"] = "auto"  # ëª¨ë¸ì´ í•„ìš” ì‹œ ë„êµ¬ í˜¸ì¶œ

                    # 1) 1ì°¨ ìŠ¤íŠ¸ë¦¼: í•„ìš” ì‹œ tool í˜¸ì¶œ ì´ë²¤íŠ¸ê°€ ë‚˜ì˜´
                    with client.responses.stream(**stream_kwargs) as stream:
                        for event in stream:
                            # í…ìŠ¤íŠ¸ ë¸íƒ€
                            if event.type == "response.output_text.delta":
                                delta = event.delta
                                if delta:
                                    full_text += delta
                                    placeholder.markdown(full_text)
                            # ë„êµ¬ í˜¸ì¶œ ìš”ì²­ ì´ë²¤íŠ¸
                            elif event.type == "response.tool_call.delta":
                                # Responses APIëŠ” ìŠ¤íŠ¸ë¦¼ ì´í›„ì— ì „ì²´ ì‘ë‹µ ê°ì²´ì—ì„œ tool_callsë¥¼ ì •ë¦¬í•´ì„œ ì£¼ê¸° ë•Œë¬¸ì—
                                # ì—¬ê¸°ì„œëŠ” ë³„ë„ ì²˜ë¦¬ë¥¼ í•˜ì§€ ì•Šê³  ì¢…ë£Œ í›„ í›„ì²˜ë¦¬ë¡œ ì¼ê´„ ì²˜ë¦¬í•œë‹¤.
                                pass
                        # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ í›„ ìµœì¢… ì‘ë‹µ(ë©”íƒ€ í¬í•¨)
                        first_response = stream.get_final_response()

                    # 2) ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš°: tool_calls íŒŒì‹± â†’ ë„êµ¬ ì‹¤í–‰ â†’ tool_outputsë¡œ ì¬í˜¸ì¶œ
                    tool_calls = []
                    try:
                        # Responses APIì˜ êµ¬ì¡°ì—ì„œ tool í˜¸ì¶œ ì •ë³´ ì¶”ì¶œ
                        if hasattr(first_response, "output") and first_response.output:
                            for item in first_response.output:
                                if item.type == "tool_call":
                                    tool_calls.append(item)
                    except Exception:
                        # ì¼ë¶€ SDK ë²„ì „/ì‘ë‹µ í˜•ì‹ ì°¨ì´ì— ëŒ€ë¹„í•œ ì•ˆì „ì¥ì¹˜
                        pass

                    if enable_tools and tool_calls:
                        # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ëª¨ìœ¼ê¸°
                        tool_outputs = []
                        for call in tool_calls:
                            name = call.name
                            arguments = call.arguments if isinstance(call.arguments, dict) else {}
                            result = execute_tool_call(name, arguments)
                            tool_outputs.append({
                                "tool_call_id": call.id,
                                "output": result
                            })

                        # tool_outputsë¥¼ ì²¨ë¶€í•´ ìµœì¢… ë‹µë³€ ìƒì„±(ë¹„ë™ê¸° X, ì¦‰ì‹œ ì¬í˜¸ì¶œ)
                        final = client.responses.create(
                            model=model,
                            input=final_messages,  # ê°™ì€ ì…ë ¥ ìœ ì§€
                            tool_choice="none",    # ì´ì œëŠ” ë„êµ¬ í˜¸ì¶œ ì•ˆ í•¨
                            tool_outputs=tool_outputs,
                            temperature=temperature,
                            max_output_tokens=max_output_tokens,
                        )

                        # ìµœì¢… í…ìŠ¤íŠ¸ë¥¼ ë®ì–´ì“°ê¸°/ì¶”ê°€
                        final_text = ""
                        if hasattr(final, "output_text"):
                            final_text = final.output_text
                        elif hasattr(final, "output") and final.output:
                            # ì¼ë¶€ SDK í˜¸í™˜
                            chunks = []
                            for item in final.output:
                                if getattr(item, "type", "") == "output_text":
                                    chunks.append(getattr(item, "content", ""))
                            final_text = "".join(chunks)

                        if final_text:
                            full_text = final_text
                            placeholder.markdown(full_text)

                except Exception as e:
                    st.error(f"ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")
                    full_text = ""

            # ì„¸ì…˜ì— ì €ì¥
            if full_text:
                st.session_state.messages.append({"role": "assistant", "content": full_text})
