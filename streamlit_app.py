import os
import time
import streamlit as st
from openai import OpenAI
from typing import List, Dict, Any

st.set_page_config(page_title="ğŸ’¬ Chatbot Ver1.0", page_icon="ğŸ’¬")

# ---- Sidebar: ì„¤ì • ----
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    # ìš°ì„ ìˆœìœ„: st.secrets â†’ í™˜ê²½ë³€ìˆ˜ â†’ ì…ë ¥ì°½
    default_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", ""))
    openai_api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        value=default_key,
        help="secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— ì €ì¥í•´ë‘ë©´ í¸í•´ìš”."
    )
    model = st.selectbox(
        "Model",
        # í•„ìš”ì‹œ ìµœì‹  ëª¨ë¸ëª…ìœ¼ë¡œ êµì²´/ì¶”ê°€í•˜ì„¸ìš”.
        options=[
            "gpt-4o-mini",      # ê°€ë²¼ìš´ ê¸°ë³¸
            "gpt-4o",           # ë” ì¢‹ì€ í’ˆì§ˆ
            "gpt-3.5-turbo",    # ë ˆê±°ì‹œ ì˜ˆì‹œ
        ],
        index=0
    )
    temperature = st.slider("Temperature", 0.0, 1.5, 0.7, 0.1)
    max_tokens = st.slider("Max output tokens", 128, 4096, 1024, 64)
    history_window = st.number_input("History turns to keep", min_value=2, max_value=50, value=12, step=1)
    system_prompt = st.text_area(
        "System prompt (ì—­í• /í†¤ ê³ ì •)",
        value="You are a helpful, concise assistant. Reply in the user's language.",
        height=120
    )

# ---- í—¤ë” ----
st.title("ğŸ’¬ Chatbot")
st.write(
    "ê°„ë‹¨í•œ Streamlit + OpenAI ì±—ë´‡ ì˜ˆì œì…ë‹ˆë‹¤. "
    "API í‚¤ëŠ” ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•˜ê±°ë‚˜ `secrets.toml`ì— ì €ì¥í•  ìˆ˜ ìˆì–´ìš”."
)

# ---- ì´ˆê¸° ì„¸ì…˜ ìƒíƒœ ----
if "messages" not in st.session_state:
    st.session_state.messages: List[Dict[str, str]] = []

# ---- ìœ í‹¸: íˆìŠ¤í† ë¦¬ ìë¥´ê¸°(í† í° ì ˆì•½ ëŒ€ìš©) ----
def window_messages(messages: List[Dict[str, str]], k: int) -> List[Dict[str, str]]:
    """
    ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ 1ê°œ + ìµœê·¼ kí„´(ì‚¬ìš©ì/ì–´ì‹œìŠ¤í„´íŠ¸ í˜ì–´)ì„ ìœ ì§€í•˜ëŠ” ê°„ë‹¨í•œ ìœˆë„ìš°ë§.
    """
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” í˜¸ì¶œë§ˆë‹¤ ìƒˆë¡œ ìƒì„±í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìµœê·¼ ëŒ€í™”ë§Œ ì˜ë¼ì„œ ë°˜í™˜
    # user/assistant ë²ˆê°ˆì•„ ìŒ“ì˜€ë‹¤ëŠ” ê°€ì •í•˜ì— ìµœê·¼ 2kê°œë§Œ ìœ ì§€
    body = messages[-2*k:] if k > 0 else messages
    return body

# ---- ìœ í‹¸: ìŠ¤íŠ¸ë¦¬ë° ìƒì„±ê¸° ----
def stream_chat(client: OpenAI, model: str, sys_prompt: str, hist: List[Dict[str, str]]):
    """
    OpenAI Chat Completions ìŠ¤íŠ¸ë¦¬ë°ì„ ê°ì‹¸ì„œ í…ìŠ¤íŠ¸ë§Œ yield.
    """
    # ìš”ì²­ ë©”ì‹œì§€ êµ¬ì„±: ì‹œìŠ¤í…œ â†’ íˆìŠ¤í† ë¦¬
    payload_messages = [{"role": "system", "content": sys_prompt}] + hist

    # ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
    stream = client.chat.completions.create(
        model=model,
        messages=payload_messages,
        temperature=temperature,
        max_tokens=max_tokens,
        stream=True,
    )

    # ì²­í¬ì—ì„œ contentë§Œ ì•ˆì „ ì¶”ì¶œ
    for chunk in stream:
        try:
            delta = chunk.choices[0].delta
            if delta and getattr(delta, "content", None):
                yield delta.content
        except Exception:
            # ì¼ë¶€ ì²­í¬ì— contentê°€ ì—†ì„ ìˆ˜ ìˆìŒ(ì—­í•  ì „í™˜ ë“±) â†’ ë¬´ì‹œ
            continue

# ---- ê¸°ì¡´ ë©”ì‹œì§€ ì¶œë ¥ ----
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ---- UI: ëŒ€í™” ì´ˆê¸°í™”/ë‚´ë³´ë‚´ê¸° ----
cols = st.columns(2)
with cols[0]:
    if st.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()
with cols[1]:
    if st.button("ğŸ’¾ ëŒ€í™” JSON ë‚´ë³´ë‚´ê¸°"):
        import json
        st.download_button(
            label="ë‹¤ìš´ë¡œë“œ",
            data=json.dumps(st.session_state.messages, ensure_ascii=False, indent=2),
            file_name=f"chat_{int(time.time())}.json",
            mime="application/json"
        )

# ---- ì…ë ¥ì°½ ----
prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦")

# ---- í‚¤ ì—†ì„ ë•Œ ì•ˆë‚´ ----
if not openai_api_key:
    st.info("ğŸ”‘ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="ğŸ—ï¸")
else:
    client = OpenAI(api_key=openai_api_key)

    if prompt:
        prompt = prompt.strip()
        if not prompt:
            st.warning("ë¹ˆ ë©”ì‹œì§€ëŠ” ë³´ë‚¼ ìˆ˜ ì—†ì–´ìš”.")
        else:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ë°˜ì˜ ë° í‘œì‹œ
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
            with st.chat_message("assistant"):
                placeholder = st.empty()
                full_text = ""

                # ìµœê·¼ íˆìŠ¤í† ë¦¬ ìœˆë„ìš°ë§
                hist = window_messages(st.session_state.messages, history_window)

                try:
                    with st.spinner("ìƒê° ì¤‘â€¦"):
                        for token in stream_chat(client, model, system_prompt, hist):
                            full_text += token
                            placeholder.markdown(full_text)
                except Exception as e:
                    st.error(f"ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")
                    full_text = ""

            # ì„¸ì…˜ì— ì €ì¥
            if full_text:
                st.session_state.messages.append({"role": "assistant", "content": full_text})
